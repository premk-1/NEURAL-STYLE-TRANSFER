# Pip install torch torchvision matplotlib pillow.

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
def loadimage(imgpath, maxsize=400, shape=None):
image = Image.open(imgpath).convert('RGB')
if max(image.size) > maxsize:
size = maxsize
else:
size = max(image.size)
if shape is not None:
size = shape
intransform = transforms.Compose([
transforms.Resize((size, size)), Transforms.Resize(size)
transforms.ToTensor(), Transforms
transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) Transforms.Normalize(mean  (0.485, 0.456, 0.406), std  (0.229, 0.224, 0.225)
])
image = intransform(image)
return image
def imconvert(tensor):
image = tensor.to("cpu").clone().detach()
image = image.numpy().squeeze()
image = image.transpose(1, 2, 0)
Image  image  np.array([0.229, 0.224, 0.225]  np.array([0.485, 0.456, 0.406]
image = image.clip(0, 1)
return image
# Load content and style images
content = loadimage('content.jpg')
style = loadimage('style.jpg', shape=[content.size(2), content.size(3)])
# Display the input images
Fig, (ax1, ax2)  plt.subplots(1, 2) figsize is (14, 7)
ax1. Plotimage(content)
ax1. Setcaption('Content Image')
ax2. Plot.imshow(style)
ax2. Setcaption('Style Image')
plt. Plot()
vgg = models.vgg19(pretrained=True).features
for param in vgg.parameters():
param.requiresgrad(False)
Device  torch.device("cuda" if torch hardware is available else "cpu")
vgg. To the device
content = content.to(device)
style = style.to(device)
Function that extracts features from layers.
def getfeatures(image, model, layers=None):
if layers is None: If layers is None:
layers = {'0': Conv1 which is 1
'5': Conv2 one
'10': Layer31
'19': Conv4-1
'21': 'conv4-2',  Content layer
'28': Convolutional block 51
features = {}
x = image
for name, layer in model.modules.items():
x = layer(x)
if name in layers:
features[layers[name]] = x
return features
def grammatrix(tensor): 
_, d, h, w = tensor.size()
tensor = tensor.view(d, h  w)
gram = torch.mm(tensor, tensor.t())
return gram
